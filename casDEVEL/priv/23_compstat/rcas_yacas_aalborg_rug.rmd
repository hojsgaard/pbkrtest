---
title: "Computer algebra systems in R:"
subtitle: "`Ryacas` and `caracas`"
author: "Mikkel Meyer Andersen and Søren Højsgaard"
date: "2020"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

---
exclude: true

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = TRUE, cache = FALSE, message = FALSE)

# devtools::load_all("~/gits/ryacas/ryacas-official/")
# devtools::install_github("mikldk/ryacas")
library(here)

library(dplyr)
library(ggplot2)
theme_set(theme_bw())

library(patchwork)
```

---

class: center, middle, inverse

# Background

---

#### `Ryacas`

* 'Yet Another Computer Algebra system' ([Yacas](http://www.yacas.org/)), 
* Initially `yacasR` (client/server-based)
* `Ryacas` on CRAN around 2009
  + Authors: Rob Goedman, Gabor Grothendieck, **Søren Højsgaard**, Ayal Pinkus, Grzegorz Mazur
  + 2017: **Mikkel Meyer Andersen** became maintainer 
    - Skip XML communication (`RForm()`)
    - [JOSS paper *Andersen and Højsgaard* (2019)](https://joss.theoj.org/papers/10.21105/joss.01763)
* Links
  + Stable version: <https://CRAN.R-project.org/package=Ryacas>
  + Development version: <https://github.com/r-cas/ryacas/>
  + Online documentation: <http://r-cas.github.io/ryacas/>

#### `caracas`

* Based on [SymPy](https://www.sympy.org/)
* '*cara*': face in Spanish (Castellano)
* Initiated in 2019
* Links
  + Development version: <https://github.com/r-cas/caracas/>
  + Online documentation: <http://r-cas.github.io/caracas/>

---


### Pros/cons

#### `Ryacas`

* Tight two-way integration
* Not as feature rich and well-tested as SymPy

#### `caracas`

* `SymPy` is a large project with many developers
* Communication is back-and-forth between R and Python (`reticulate` to the rescue!)

#### Similarities

* Both works by creating symbols (`Ryacas::ysym()`/`caracas::symbol()`) and 
  use S3 generics to use these as normal R objects.

---

This talk:

* `caracas`: Main content
* `Ryacas`: Online math exercises using Shiny

---

class: center, middle, inverse

# Getting started

---

### Getting started

```{r}
library(caracas)
```

This talk was made using the development version available at <https://github.com/r-cas/caracas/>:

```{r, eval = FALSE}
devtools::install_github("r-cas/caracas")
```

```{r}
packageVersion("caracas")
```



---

### Symbols

```{r}
x <- symbol("x") #<<
y <- symbol("y")
eq <- x^2 + 3*x + 4*y + y^4
eq
as.character(eq)
as_r(eq)
tex(eq)
```

---

### Derivatives

```{r}
dd(eq, x) # eq = x^2+3*x+4*y+y^4
H <- dd2(eq, c(x, y)) # Hessian
H
print(H, ascii = TRUE) # options(caracas.print.ascii = TRUE)
```

---

```{r}
tex(H)
# $$H = `r tex(H)`$$
```

$$H = `r tex(H)`$$

```{r}
eval(as_r(H), list(x = 1, y = 1))
```

---

### Solving equations

Syntax:
```
solve_lin(A, b) # Ax = b
solve_sys(lhs, rhs, vars) # lhs = rhs for vars
```

A brief example:

```{r}
sol <- solve_sys(x^2, -1, x)
sol
as_r(sol[[1]]$x)
```

---

### Solving a system of non-linear equations


```{r}
x <- symbol("x")
y <- symbol("y")
lhs <- cbind(3*x*y - y, x)
t(lhs)
rhs <- cbind(-5*x, y+4)
t(rhs)
```

$$\begin{align}
`r tex(lhs[, 1L])` &= `r tex(rhs[, 1L])` \\
`r tex(lhs[, 2L])` &= `r tex(rhs[, 2L])`
\end{align}$$

---

```{r}
sol <- solve_sys(lhs, rhs, c(x, y))
sol
as_r(sol[[1]]$x)
as_r(sol[[1]]$y)
```

---

### Integrals

<!--- here --->

Syntax:
```
intf(expr, var, [from, to], doit = TRUE)
```

```{r}
x <- symbol("x")
res <- intf(1/x, x)
res
res <- intf(1/x, x, doit = FALSE)
res
tex(res)
doit(res)
as_r(res) # doit() is automatically called
```

---

### Sums

Syntax:
```
sumf(expr, var, [from, to], doit = TRUE)
```

```{r}
k <- symbol("k")
res <- sumf(k, k, 0, "n")
res
simplify(res)
```

---

### Sums

```{r}
k <- symbol("k")
res <- sumf(1/k^2, "k", 1, Inf)
res
as_r(res)
```

---

### Limits 

Syntax:
```
lim(expr, [var, to], dir = "-", doit = TRUE)
```

```{r}
x <- symbol("x")
lim(sin(x)/x, x, 0)
lim(1/x, x, 0)
l <- lim(1/x, x, 0, dir = "-", doit = FALSE)
l
tex(l)
doit(l)
```

---

### Linear algebra

```{r}
A <- as_symbol(matrix(c(2, 1, 4, "x"), 2, 2))
A
t(A)
A[1, ]
```

---

```{r}
inv(A) # or solve_lin(A)
determinant(A)
```

---

```{r}
b <- as_symbol(c("x", 3))
y <- A %*% b
y
solve_lin(A, y)
solve_lin(A, y) %>% simplify() # == b
```

---

class: inverse, center, middle

# Example: Multinomial likelihood

---

### Multinomial likelihood

The multinomial likelihood for three categories is

$$\text{lik}(p \mid y) \propto p_1^{y_1} p_2^{y_2} p_3^{y_3}.$$

Taking $\log$ we get 

\begin{align}
  l(p) &= y_1 \log(p_1) + y_2 \log(p_2) + y_3 \log(p_3) \\
  g(p) &= p_1 + p_2 + p_3 - 1 .
\end{align}

Maximise $l(p)$ for $g(p) = 0$ using Lagrange multiplier to get the unconstrainted optimisation problem
\begin{align}
  L = -l(p) + \lambda g(p)
\end{align}

```{r}
p <- as_symbol(paste0("p", 1:3))
y <- as_symbol(paste0("y", 1:3))
a <- as_symbol("a")
l <- sum(y*log(p))
L <- -l + a*(sum(p) - 1)
L
```

---

### Multinomial likelihood

```{r}
gL <- dd(L, c("a", paste0("p", 1:3)))
sol <- solve_sys(gL, c("p1", "p2", "p3", "a"))
sol
```

---
class: inverse, center, middle

# Example: Graphical models

---

.pull-left[
```{tikz, graphmodel, fig.ext = 'svg', cache=TRUE, echo = FALSE, fig.align="center"}
\begin{tikzpicture}[node distance=2cm,auto,-,thick,scale=1.5]
\begin{scope}[every node/.style={circle,thick,draw,line width=1pt,scale=1.5}]
\node (B) {$B$};
\node (D) [left of=B] {$D$};
\node (C) [below of=B] {$C$};
\node (E) [below of=D] {$E$};
\node (A) [above of=D] {$A$};
\end{scope}
\draw[] (A) to node {} (B);
\draw[] (A) to node {} (D);
\draw[] (B) to node {} (D);
\draw[] (D) to node {} (E);
\draw[] (E) to node {} (C);
\end{tikzpicture}
```
]

.pull-right[
* Multivariate models with focus on conditional independence (CI) restrictions.
* Suppose $X=(X_A, X_B, \dots, X_E) \sim N_5(0, \Sigma)$.
* The key to interpretation is the concentration matrix $K=\Sigma^{-1}$
* $K_{ij}=0$ iff $X_i$ and $X_j$ are independent given all other $X$s
* A missing edge reflects a CI-restriction.
]

* For example $X_D$ and $X_C$ are independent given all other $X$s
* A practical approach: $X_C$ and $X_D$ may be correlated. However 
  + Regress $X_D$ on $X_A, X_B, X_E$ and extract residuals $r_D$. 
  + Regress $X_C$ on $X_A, X_B, X_E$ and extract residuals $r_C$. 
  + If the resuduals $r_D$ and $r_C$ are uncorrelated then we have the CI.

---

Many classical statistical models are built up on "modularization" based on CI-restrictions:

Examples:

* Autoregressive models
* State-space models / dynamic linear models
* Naive Bayesian models
* Probabilistic Principal Components

It is illustrative to see the connection between these model classes and CI-restrictions in the multivariate normal distribution.



---

## Autoregression, AR(1)

```{tikz, ar1, fig.ext = 'svg', cache=TRUE, echo = FALSE, fig.align="center"}
\usetikzlibrary{arrows}
\usetikzlibrary{arrows.meta}
\begin{tikzpicture}[node distance=2cm,auto,-{Latex[length=3mm, width=3mm]},thick,scale=1.5]
\begin{scope}[every node/.style={circle,thick,draw,line width=1pt,scale=1.5}]
\node (x1) {$x_1$};
\node (x2) [right of=x1] {$x_2$};
\node (x3) [right of=x2] {$x_3$};
\node (x4) [right of=x3] {$x_4$};
\end{scope}
\draw[] (x1) to node {} (x2);
\draw[] (x2) to node {} (x3);
\draw[] (x3) to node {} (x4);
\end{tikzpicture}
```

```{r, echo=FALSE, results="hide"}
L <- as_symbol("[[1,0,0,0],[-a,1,0,0],[0,-a,1,0],[0,0,-a,1]]")
L
x <- t(as_symbol("[[x1,x2,x3,x4]]"))
x
e <- t(as_symbol("[[e1,e2,e3,e4]]"))
e
```


Consider $AR(1)$ process: $x_i = a x_{i-1} + e_i$ where $i=2,3,4$ and where $x_1=e_1$.
$$\begin{align}
x_1 &=e_1 \\
x_2 &= a x_{1} + e_2 \\
x_3 &= a x_{2} + e_3 \\
x_4 &= a x_{3} + e_4
\end{align}$$

Let $e=(e_1, \dots, e_4)$ and $x=(x_1, \dots x_4)$. 
Isolating error terms gives that
$$\begin{align}
e = `r tex(e)` = `r tex(L)` `r tex(x)` = L x
\end{align}$$

---

Define $L$:
```{r}
L <- as_symbol("[[1,0,0,0],[-a,1,0,0],[0,-a,1,0],[0,0,-a,1]]")
L
```

```{tikz, ref.label="ar1", fig.ext = 'svg', cache=TRUE, echo = FALSE, fig.align="center"}
```


If error terms $e_i$ are independent and $N(0,v^2)$ then $e = L x$ gives

* $\mathbf{Var}(e)= v^2 I = L \mathbf{Var}(x) L'$ 

* Hence the covariance matrix of $x$ is $V=\mathbf{Var}(x) = v^2 L^{-1} (L^{-1})'$

* The concentration matrix is $K=V^{-1}=L L'/v^2$


We skip $v^2$ in the following (set $v^2=1$)


---

```{r}
Li <- inv(L) # or solve_lin(L)
Li
V <- Li %*% t(Li)
K <- L %*% t(L)
```


$$\begin{align}
K &= `r tex(K)`  \\
V &= `r tex(V)`  \\
\end{align}$$

---

The pattern of $0$s in $K$ is important:

```{r}
K
```


$K_{ij}=0$ iff $x_i$ is independent of $x_j$ given all other $x$'s

```{tikz, ref.label="ar1", fig.ext = 'svg', cache=TRUE, echo = FALSE, fig.align="center"}
```

---

## State space models

```{tikz, ssm, fig.ext = 'svg', cache=TRUE, echo = FALSE, fig.align="center"}
\usetikzlibrary{arrows}
\usetikzlibrary{arrows.meta}
\begin{tikzpicture}[node distance=2cm,auto,-{Latex[length=3mm, width=3mm]},thick,scale=1.5]
\begin{scope}[every node/.style={circle,thick,draw,line width=1pt,scale=1.5}]
\node (x1) {$x_1$};
\node (x2) [right of=x1] {$x_2$};
\node (x3) [right of=x2] {$x_3$};
\node (x4) [right of=x3] {$x_4$};
\node (y2) [below of=x2] {$y_2$};
\node (y3) [below of=x3] {$y_3$};
\node (y4) [below of=x4] {$y_4$};
\end{scope}
\draw[] (x1) to node {} (x2);
\draw[] (x2) to node {} (x3);
\draw[] (x3) to node {} (x4);
\draw[] (x2) to node {} (y2);
\draw[] (x3) to node {} (y3);
\draw[] (x4) to node {} (y4);
\end{tikzpicture}
```

Same story, except that the setting is slightly more involved:

$$\begin{align}
x_i &= a x_{i-1} + e_i \\
y_i &= b x_{i} + u_i
\end{align}$$

This gives a different $L$, but the method to find the concentration matrix is as before.


---
class: inverse, center, middle

# Further down the road


---

# References


* Yacas (**y**et **a**nother **c**omputer **a**lgebra **s**ystem): <http://www.yacas.org/>
  + Online docs: <http://yacas.readthedocs.org/>
* Stable version: <https://CRAN.R-project.org/package=Ryacas>
* Development version: <https://github.com/mikldk/ryacas/>
  + Online docs: <http://mikldk.github.io/ryacas/>

