% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pbkr_pb_modcomp.R
\name{pb2_modcomp}
\alias{pb2_modcomp}
\title{Parametric Bootstrap Model Comparison}
\usage{
pb2_modcomp(
  fit1,
  fit0,
  nsim = 1000,
  sequential = FALSE,
  h = 20,
  engine = "serial",
  nworkers = 2,
  verbose = FALSE
)
}
\arguments{
\item{fit1}{The larger (alternative) model.}

\item{fit0}{The smaller (null) model.}

\item{nsim}{Number of simulations. In fixed bootstrap: total number of simulations. In sequential bootstrap: maximum number of simulations allowed.}

\item{sequential}{Logical; if TRUE, use sequential bootstrap sampling to reach target number of extreme hits.}

\item{h}{Number of extreme hits to target in sequential sampling.}

\item{engine}{Parallelisation engine: "serial", "parallel", or "future".}

\item{nworkers}{Number of workers for parallel/future engine.}

\item{verbose}{Logical; if TRUE, print progress messages.}
}
\value{
An object of class \code{PBmodcomp}, with print(), summary(), and plot() methods.
}
\description{
Compare two nested models using parametric bootstrap simulation of the likelihood ratio statistic.
Supports models fitted via lm, lme4 (lmer/glmer), nlme (lme/gls), etc.
}
\details{
The models should both be fitted by maximum likelihood (not REML). If REML was used,
the function will automatically refit with REML = FALSE where possible.
}
\note{
\strong{Best Practice:} Always fit your models with the \verb{data=} argument.
This ensures all covariates used in the model formula are stored with the model object,
enabling reliable simulation and refitting for bootstrap analysis,
including on parallel workers. Without \verb{data=}, refitting may fail in parallel contexts
and reproducibility is compromised.
}
\examples{
if (requireNamespace("lme4") && requireNamespace("nlme")) {
  data(sleepstudy, package = "lme4")
  sleepstudy$Days2 <- sleepstudy$Days^2

  # LM example
  lm_fit1 <- lm(Reaction ~ Days + Days2, data = sleepstudy)
  lm_fit0 <- update(lm_fit1, . ~ . - Days2)
  set.seed(42)
  res_lm <- pb2_modcomp(lm_fit1, lm_fit0, nsim = 200)
  res_lm
  summary(res_lm)
  plot(res_lm, show.chisq=TRUE)

  # GLS example
  gls_fit1 <- nlme::gls(Reaction ~ Days + Days2, data = sleepstudy, method = "ML")
  gls_fit0 <- update(gls_fit1, . ~ . - Days2)
  set.seed(42)
  res_gls <- pb2_modcomp(gls_fit1, gls_fit0, nsim = 200)
  res_gls
  summary(res_gls)
  plot(res_gls, show.chisq=TRUE)

  # LME example
  lme_fit1 <- nlme::lme(Reaction ~ Days + Days2, random = ~ 1 | Subject,
                        data = sleepstudy, method = "ML")
  lme_fit0 <- update(lme_fit1, . ~ . - Days2)
  set.seed(42)
  res_lme <- pb2_modcomp(lme_fit1, lme_fit0, nsim = 200)
  res_lme
  summary(res_lme)
  plot(res_lme, show.chisq=TRUE)

  # LMER example (lme4)
  lmer_fit1 <- lme4::lmer(Reaction ~ Days + Days2 + (1 | Subject),
                          data = sleepstudy, REML = FALSE)
  lmer_fit0 <- update(lmer_fit1, . ~ . - Days2)
  set.seed(42)
  res_lmer <- pb2_modcomp(lmer_fit1, lmer_fit0, nsim = 200)
  res_lmer
  summary(res_lmer)
  plot(res_lmer, show.chisq=TRUE)

  # Sequential example
  set.seed(42)
  res_seq <- pb2_modcomp(lmer_fit1, lmer_fit0, sequential = TRUE, h = 20, nsim = 500)
  res_seq
  summary(res_seq)
  plot(res_seq, show.chisq=TRUE)

}
}
